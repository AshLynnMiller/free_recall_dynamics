---
title: "Converting SPSS syntax to R"
author: "Ashley L. Miller"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    theme: spacelab
    toc: true
    toc_float: true
    toc_depth: 5
    code_folding: show
---

```{r setup, include=FALSE}
# Set knitr options
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      fig.width = 7,
                      fig.height = 5,
                      fig.align = "center")

# disable scientific notation
options(scipen = 999)

# load packages
library(devtools)
library(tidyverse)
#library(lme4)
library(rio)
library(here)
library(magrittr)
#library(lmerTest)
#devtools::install_github("datalorax/sundry")
library(sundry) #contains nice function for computing standard errors
library(knitr)
library(kableExtra)
library(zoo)
library(extrafont)

# import fonts
# font_import() # only run once

# check fonts 
fonts()

# register fonts
loadfonts(device = "all")
```

```{r include=FALSE}

# Load personal theme for plots
ashTheme <- theme(axis.title.y = element_text(size = 12.85,
                                              family = ".SF NS Rounded",
                                              face = "bold"),
                  axis.title.x = element_text(size = 12.85,
                                              face = "bold",
                                              family = ".SF NS Rounded"),
                  axis.text.y = element_text(size = 12,
                                             face = "bold",
                                             family = ".SF NS Rounded"),
                  axis.text.x = element_text(size = 12, 
                                             family = ".SF NS Rounded"),
                  strip.text = element_text(face = "bold",
                                            size = 13,
                                            family = ".SF NS Rounded"),
                  plot.title = element_text(size = 13.5,
                                            hjust = 0.5, 
                                            face = "bold",
                                            family = ".SF NS Rounded"),
                  plot.subtitle = element_text(hjust = 0.5,
                                               size = 13,
                                               family = ".SF NS Rounded"),
                  plot.caption = element_text(hjust = 0.5, 
                                              size = 12,
                                              family = ".SF NS Rounded"),
                  legend.title = element_text(size = 12,
                                              face = "bold",
                                              family = ".SF NS Rounded"),
                  legend.text = element_text(size = 12,
                                             family = ".SF NS Rounded"))
```

### Load data

```{r load_raw_data}
recall_data <- import(here::here("data",
                                 "AshRawDFRDemo.sav"),
                      setclass = "tibble") %>%
  janitor::clean_names() %>%
  dplyr::rename("error_type" = "err_pliel_ior_r")
```

### Take a quick look at the data (for html view)

Data file is currently in long format:

- Total number of rows 978
- Total number of participants: 33 (this is a subset of a larger dataset)
- Total number word lists: 5
- Total number of words per list: 10 (so serpos ranges from 1-10)

```{r}
# there is no need to run this if you are rerunning code in the .Rmd file
# I'm just making it easy to view data in html output
recall_data %>%
  kbl() %>%
  kable_styling(bootstrap_options = c("condensed", "responsive"),
                full_width = F) %>%
  column_spec(1, bold = T, border_right = T) %>%
  column_spec(2, width = "40em") %>%
  scroll_box(width = "100%", height = "225px")
```

### Tidy and clean data to compute `probability of first recall (PFR)`

PFR is simply the number of times the first word recalled comes from a given serial position divided by the number of times the first recalled word could have come from that serial position.

Note, `subtrial` is simply output position. However, this variable was added manually by the person who coded the data, meaning it could be prone to errors. When tidying the data, I will create a new variable, `output_position`, to replace the existing `subtrial` variable.


#### First we need to create variables that indicate when a change in list occurred (i.e, when a mismatch occurs between list and lag_list)

```{r}
recall_data %<>%
  mutate(list_lag = lag(list)) %>%
  select(subject, list, list_lag, subtrial, serpos, acc, error_type,
         recall_onset_time, recall_rt_time)

# replace missing value in first row with 0
recall_data %<>%
  mutate(list_lag = replace_na(list_lag, 0))
```

```{r}
# there is no need to run this if you are rerunning code in the .Rmd file
# I'm just making it easy to view data in html output
recall_data %>%
  kbl() %>%
  kable_styling(bootstrap_options = c("condensed", "responsive"),
                full_width = F) %>%
  column_spec(1, bold = T, border_right = T) %>%
  column_spec(2, width = "40em") %>%
  scroll_box(width = "100%", height = "225px")
```

```{r}
recall_data %<>%
  mutate(subtrial2 = case_when((list != list_lag) ~ 1)) %>%
  select(subject, list, list_lag, subtrial2, subtrial, serpos, acc, error_type,
         recall_onset_time, recall_rt_time)

# replace missing value with 0
recall_data %<>%
  mutate(subtrial2 = replace_na(subtrial2, 0))
```

```{r}
# there is no need to run this if you are rerunning code in the .Rmd file
# I'm just making it easy to view data in html output
recall_data %>%
  kbl() %>%
  kable_styling(bootstrap_options = c("condensed", "responsive"),
                full_width = F) %>%
  column_spec(1, bold = T, border_right = T) %>%
  column_spec(2, width = "40em") %>%
  scroll_box(width = "100%", height = "225px")
```

#### Now that we know when each new list began, we can count the number of words outputted within each list

```{r}
recall_data %<>%
  group_by(subject, list) %>%
  mutate(
    # Cumulative sum of subtrial2, which effectively identifies each block
    new_list = cumsum(subtrial2),
      # Identify the start of a new block
      output_position = ifelse(subtrial2 == 1, 1, NA),
        output_position = 
        # Propagate the starting value and add the counter
        zoo::na.locf(output_position, 
                     na.rm = FALSE) + 
                     row_number() - match(output_position, output_position),
    output_position = ifelse(subtrial2 == 1,
                             output_position - 1, output_position)) %>%
  ungroup() %>%
  select(subject, list, list_lag, subtrial2, new_list, output_position, 
         subtrial, serpos, acc, error_type, recall_onset_time, recall_rt_time)

# I don't want each output position to begin with 0, so I will add 1 to each existing value
# I will also drop the columns that are no longer needed
recall_data %<>%
  mutate(output_position = output_position + 1) %>%
  select(-list_lag,
         -new_list,
         -subtrial2,
         -subtrial)
```

```{r}
# there is no need to run this if you are rerunning code in the .Rmd file
# I'm just making it easy to view data in html output
recall_data %>%
  kbl() %>%
  kable_styling(bootstrap_options = c("condensed", "responsive"),
                full_width = F) %>%
  column_spec(1, bold = T, border_right = T) %>%
  column_spec(2, width = "40em") %>%
  scroll_box(width = "100%", height = "225px")
```

#### If you want data in wide format (aggregated across lists), you will need to do the following:

```{r}
recall_data %<>%
   mutate(PFR_SP1 = case_when((output_position == 1 & serpos == 1) ~ 1,
                              (output_position == 1 & serpos != 1) ~ 0),
          PFR_SP2 = case_when((output_position == 1 & serpos == 2) ~ 1,
                              (output_position == 1 & serpos != 2) ~ 0),
          PFR_SP3 = case_when((output_position == 1 & serpos == 3) ~ 1,
                              (output_position == 1 & serpos != 3) ~ 0),
          PFR_SP4 = case_when((output_position == 1 & serpos == 4) ~ 1,
                              (output_position == 1 & serpos != 4) ~ 0),
          PFR_SP5 = case_when((output_position == 1 & serpos == 5) ~ 1,
                              (output_position == 1 & serpos != 5) ~ 0),
          PFR_SP6 = case_when((output_position == 1 & serpos == 6) ~ 1,
                              (output_position == 1 & serpos != 6) ~ 0),
          PFR_SP7 = case_when((output_position == 1 & serpos == 7) ~ 1,
                              (output_position == 1 & serpos != 7) ~ 0),
          PFR_SP8 = case_when((output_position == 1 & serpos == 8) ~ 1,
                              (output_position == 1 & serpos != 8) ~ 0),
          PFR_SP9 = case_when((output_position == 1 & serpos == 9) ~ 1,
                              (output_position == 1 & serpos != 9) ~ 0),
         PFR_SP10 = case_when((output_position == 1 & serpos == 10) ~ 1,
                              (output_position == 1 & serpos != 10) ~ 0))
```

```{r}
PFR <- recall_data %>%
  filter(output_position == 1) %>%
  group_by(subject) %>%
  summarize(PFR_SP1_sum = sum(PFR_SP1),
            PFR_SP2_sum = sum(PFR_SP2),
            PFR_SP3_sum = sum(PFR_SP3),
            PFR_SP4_sum = sum(PFR_SP4),
            PFR_SP5_sum = sum(PFR_SP5),
            PFR_SP6_sum = sum(PFR_SP6),
            PFR_SP7_sum = sum(PFR_SP7),
            PFR_SP8_sum = sum(PFR_SP8),
            PFR_SP9_sum = sum(PFR_SP9),
            PFR_SP10_sum = sum(PFR_SP10))

# this is the format  your data needs to be in to run analyses in SPSS
PFR %<>%
  # dividing by 5 because there were 5 total lists, meaning each serpos (1-10) could only be recalled the first 5 times at the most
  mutate(SP1_PFR = PFR_SP1_sum/5,
         SP2_PFR = PFR_SP2_sum/5,
         SP3_PFR = PFR_SP3_sum/5,
         SP4_PFR = PFR_SP4_sum/5,
         SP5_PFR = PFR_SP5_sum/5,
         SP6_PFR = PFR_SP6_sum/5,
         SP7_PFR = PFR_SP7_sum/5,
         SP8_PFR = PFR_SP8_sum/5,
         SP9_PFR = PFR_SP9_sum/5,
         SP10_PFR = PFR_SP10_sum/5) %>%
  select(-ends_with("_sum"))

PFR_agg <- PFR %>%
  gather(key = serpos, value = PFR, SP1_PFR:SP10_PFR) %>%
  mutate(serpos = parse_number(serpos)) %>%
  arrange(subject, serpos)

#removing widest form of the data
rm(PFR)
```

```{r}
# there is no need to run this if you are rerunning code in the .Rmd file
# I'm just making it easy to view data in html output
PFR_agg %>%
  kbl() %>%
  kable_styling(bootstrap_options = c("condensed", "responsive"),
                full_width = F) %>%
  column_spec(1, bold = T, border_right = T) %>%
  column_spec(2, width = "40em") %>%
  scroll_box(width = "100%", height = "225px")
```

#### Let's graph the data to make it sure looks right

```{r}
PFR_agg %>%
  group_by(serpos) %>%
  summarize(mean_PFR = mean(PFR, na.rm = TRUE),
            se_PFR = se(PFR)) %>%
  ggplot(aes(serpos, mean_PFR)) +
  geom_point(colour = "#D32254", size = 2) +
  geom_line(colour = "#D32254", linewidth = 1) +
  geom_ribbon(aes(ymin = mean_PFR - se_PFR,
                  ymax = mean_PFR + se_PFR),
              fill = "#DE3163",
              alpha = 0.7) +
  theme_bw(base_size = 14) +
  labs(y = "Probability of First Recall",
       x = "\nSerial Position") +
  scale_x_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10),
                     labels = c("1", "2", "3", "4", "5", 
                                "6", "7", "8", "9", "10")) +
  scale_y_continuous(breaks = c(0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6),
                     labels = c(".00", ".10", ".20", ".30", 
                                ".40", ".50", ".60"),
                     limits = c(.00, NA)) +
  ashTheme
```

### Tidy and clean data to compute `IRTs` and `recall latency`

```{r}
recall_data %<>%
  mutate(start = case_when((output_position == 1) ~ recall_onset_time)) %>%
  fill(start) # Fill NA's with the preceding non-NA values

recall_data %<>%
  dplyr::rename("rt_time" = "recall_rt_time")

recall_data %<>%
  select(subject:rt_time, start, PFR_SP1:PFR_SP10)
```

```{r}
# there is no need to run this if you are rerunning code in the .Rmd file
# I'm just making it easy to view data in html output
recall_data %>%
  kbl() %>%
  kable_styling(bootstrap_options = c("condensed", "responsive"),
                full_width = F) %>%
  column_spec(1, bold = T, border_right = T) %>%
  column_spec(2, width = "40em") %>%
  scroll_box(width = "100%", height = "225px")
```

```{r}
# in terms of the number of items output to include, most ss (99.3%) in the present dataset enter 15 or fewer responses per list (this is the value typically used for Nash). But in the present dataset,  there are a few instances in which a participant entered up to 20 responses… there is even someone who entered up to 25 responses in a single list (when there was only 10 TBR items shown per list)...

recall_data %<>%
  mutate(rt = case_when((output_position == 1 & rt_time > 0) ~ rt_time - start,
                        (output_position == 2 & rt_time > 0) ~ rt_time - start,
                        (output_position == 3 & rt_time > 0) ~ rt_time - start,
                        (output_position == 4 & rt_time > 0) ~ rt_time - start,
                        (output_position == 5 & rt_time > 0) ~ rt_time - start,
                        (output_position == 6 & rt_time > 0) ~ rt_time - start,
                        (output_position == 7 & rt_time > 0) ~ rt_time - start,
                        (output_position == 8 & rt_time > 0) ~ rt_time - start,
                        (output_position == 9 & rt_time > 0) ~ rt_time - start,
                        (output_position == 10 & rt_time > 0) ~ rt_time - start,
                        (output_position == 11 & rt_time > 0) ~ rt_time - start,
                        (output_position == 12 & rt_time > 0) ~ rt_time - start,
                        (output_position == 13 & rt_time > 0) ~ rt_time - start,
                        (output_position == 14 & rt_time > 0) ~ rt_time - start,
                        (output_position == 15 & rt_time > 0) ~ rt_time - start,
                        (output_position == 16 & rt_time > 0) ~ rt_time - start,
                        (output_position == 17 & rt_time > 0) ~ rt_time - start,
                        (output_position == 18 & rt_time > 0) ~ rt_time - start,
                        (output_position == 19 & rt_time > 0) ~ rt_time - start,
                        (output_position == 20 & rt_time > 0) ~ rt_time - start,
                        (output_position == 21 & rt_time > 0) ~ rt_time - start,
                        (output_position == 22 & rt_time > 0) ~ rt_time - start,
                        (output_position == 23 & rt_time > 0) ~ rt_time - start,
                        (output_position == 24 & rt_time > 0) ~ rt_time - start,
                        (output_position == 25 & rt_time > 0) ~ rt_time - start))

recall_data %<>%
  select(subject:rt_time, start, rt, PFR_SP1:PFR_SP10)

# latency to the first response is merely rt when output position = 1
# mean recall latency is mean rt
```

```{r}
# there is no need to run this if you are rerunning code in the .Rmd file
# I'm just making it easy to view data in html output
recall_data %>%
  kbl() %>%
  kable_styling(bootstrap_options = c("condensed", "responsive"),
                full_width = F) %>%
  column_spec(1, bold = T, border_right = T) %>%
  column_spec(2, width = "40em") %>%
  scroll_box(width = "100%", height = "225px")
```

```{r}
# calculate overall IRT based on RT (time between consecutive retrievals)
recall_data %<>%
  mutate(IRT = case_when((output_position != 1) ~ rt - lag(rt)))

recall_data %<>%
  mutate(IRT = replace_na(IRT, 0)) %>%
  select(subject:rt, IRT, PFR_SP1:PFR_SP10)

#convert ms to s
recall_data %<>%
  mutate(IRT = IRT/1000)

#convert ms to s
recall_data %<>%
  mutate(rt = rt/1000)
```

```{r}
# there is no need to run this if you are rerunning code in the .Rmd file
# I'm just making it easy to view data in html output
recall_data %>%
  kbl() %>%
  kable_styling(bootstrap_options = c("condensed", "responsive"),
                full_width = F) %>%
  column_spec(1, bold = T, border_right = T) %>%
  column_spec(2, width = "40em") %>%
  scroll_box(width = "100%", height = "225px")
```

#### Visualize IRTs

```{r}
recall_data %>%
  filter(output_position < 7) %>%
  group_by(output_position) %>%
  summarize(mean_IRT = mean(IRT, na.rm = TRUE),
            se_IRT = se(IRT)) %>%
  ggplot(aes(output_position, mean_IRT)) +
  geom_point(colour = "#ADADFF", size = 2) +
  geom_line(colour = "#ADADFF", linewidth = 1) +
  geom_ribbon(aes(ymin = mean_IRT - se_IRT,
                  ymax = mean_IRT + se_IRT),
              fill = "#CCCCFF",
              alpha = 0.7) +
  theme_bw(base_size = 14) +
  labs(y = "Mean Interresponse Time (s)",
       x = "\nOutput Position") +
  scale_x_continuous(breaks = c(0, 1, 2, 3, 4, 5, 6),
                     labels = c("0", "1", "2", "3", "4", "5", "6")) +
  scale_y_continuous(breaks = c(0, 1, 2, 3, 4, 5, 6),
                     labels = c("0", "1", "2", "3", "4", "5", "6"),
                     limits = c(.00, NA)) +
  ashTheme
```


#### Visualize recall latency

```{r}
recall_data %>%
  filter(output_position < 7) %>%
  group_by(output_position) %>%
  summarize(mean_rt = mean(rt, na.rm = TRUE),
            se_rt = se(rt)) %>%
  ggplot(aes(output_position, mean_rt)) +
  geom_point(colour = "#6495ED", size = 2) +
  geom_line(colour = "#6495ED", linewidth = 1) +
  geom_ribbon(aes(ymin = mean_rt - se_rt,
                  ymax = mean_rt + se_rt),
              fill = "#7FA7F0",
              alpha = 0.7) +
  theme_bw(base_size = 14) +
  labs(y = "Mean Recall Latency (s)",
       x = "\nOutput Position") +
  scale_x_continuous(breaks = c(0, 1, 2, 3, 4, 5, 6),
                     labels = c("0", "1", "2", "3", "4", "5", "6")) +
  scale_y_continuous(breaks = c(4, 6, 8, 10, 12, 14, 16, 18, 20),
                     labels = c("4", "6", "8", "10", "12","14",
                                "16", "18", "20"),
                     limits = c(NA, NA)) +
  ashTheme
```


#### Run the following if you need wide data aggregated across lists 

```{r}
rt_agg <- recall_data %>%
  filter(output_position < 7) %>%
  group_by(subject, output_position) %>%
  summarize(mean_IRT = mean(IRT, na.rm = TRUE),
            mean_recall_latency = mean(rt, na.rm = TRUE))
```

### Export data for whatever program you use to analyze data

I will export a csv file as an example

```{r}
rio::export(recall_data, here::here("data",
                                    "demo_recall_long.csv"))
```

